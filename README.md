# ğŸ“° Fake News Classification App


This is a machine learning project that detects whether a news article is **real** or **fake** using Natural Language Processing (NLP) and Logistic Regression. It uses a trained model with TF-IDF vectorization and is deployed using Streamlit.


## ğŸš€ Live Demo

Try it here:  
ğŸ‘‰ [Fake News Classifier](https://newsarticleclassification-dwscabcvvfvdxez7xs24x6.streamlit.app/)

![image](https://github.com/user-attachments/assets/13d97970-2521-4e05-8d19-06525bfd8cfb)



## ğŸ“‚ Dataset Used

This project uses the **Fake and Real News Dataset** from Kaggle:

- ğŸ“„ **Fake.csv** â€“ News marked as fake
- ğŸ“„ **True.csv** â€“ News marked as real

ğŸ”— [Kaggle Dataset Link](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset?select=Fake.csv)

> âš ï¸ These files are **not included in the repository** due to GitHubâ€™s file size limits (>25MB).  
> You can download them manually from Kaggle or this shared cloud link:


## ğŸ§  How It Works

1. Text from each news article is **cleaned and preprocessed**.
2. Articles are transformed using **TF-IDF vectorization**.
3. A **Logistic Regression model** (with class balancing) is trained on the processed data.
4. In the app, users paste an article, and the model predicts whether itâ€™s **Real or Fake**.


## âš ï¸ Missing Files Explanation

| File         | Included in GitHub? | Why |
|--------------|----------------------|-----|
| `model.pkl`  | âœ… Yes               | Pretrained model file |
| `tfidf.pkl`  | âœ… Yes               | TF-IDF vectorizer used for predictions |
| `Fake.csv`   | âŒ No                | File too large (>25MB) |
| `True.csv`   | âŒ No                | File too large (>25MB) |

You do not need the CSV files to use the **app**, only for retraining the model.

---

## ğŸ› ï¸ Run Locally

1. Clone the repository
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
